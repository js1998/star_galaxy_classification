{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils import data\n",
    "from astropy.nddata.utils import Cutout2D\n",
    "import glob, os\n",
    "from esutil import wcsutil\n",
    "from astropy.table import Table\n",
    "import pandas as pd\n",
    "import fitsio\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "from random import randint\n",
    "import math\n",
    "import sys\n",
    "from astropy.visualization import hist\n",
    "from torch.utils.data import DataLoader\n",
    "from astroML.datasets import fetch_imaging_sample, fetch_sdss_S82standards\n",
    "import torch.nn.functional as F\n",
    "import skimage\n",
    "from tensorboardX import SummaryWriter\n",
    "from astropy.visualization import MinMaxInterval, SqrtStretch, ZScaleInterval, ImageNormalize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "# ----------------------------------------\n",
    "# Global variables within this script\n",
    "arg_lists = []\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "\n",
    "def str2bool(v):\n",
    "    return v.lower() in (\"true\", \"1\")\n",
    "\n",
    "\n",
    "def add_argument_group(name):\n",
    "    arg = parser.add_argument_group(name)\n",
    "    arg_lists.append(arg)\n",
    "    return arg\n",
    "\n",
    "\n",
    "# ----------------------------------------\n",
    "# Arguments for the main program\n",
    "main_arg = add_argument_group(\"Main\")\n",
    "\n",
    "\n",
    "main_arg.add_argument(\"--mode\", type=str,\n",
    "                      default=\"test\",\n",
    "                      choices=[\"train\", \"test\"],\n",
    "                      help=\"Run mode\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# Arguments for training\n",
    "train_arg = add_argument_group(\"Training\")\n",
    "\n",
    "\n",
    "train_arg.add_argument(\"--data_dir\", type=str,\n",
    "                       default=\"/Users/kwang/Downloads/cifar-10-batches-py\",\n",
    "                       help=\"Directory with CIFAR10 data\")\n",
    "\n",
    "train_arg.add_argument(\"--learning_rate\", type=float,\n",
    "                       default=1e-5,\n",
    "                       help=\"Learning rate (gradient step size)\")\n",
    "\n",
    "train_arg.add_argument(\"--batch_size\", type=int,\n",
    "                       default=1,\n",
    "                       help=\"Size of each training batch\")\n",
    "\n",
    "train_arg.add_argument(\"--num_epoch\", type=int,\n",
    "                       default=15,\n",
    "                       help=\"Number of epochs to train\")\n",
    "\n",
    "train_arg.add_argument(\"--val_intv\", type=int,\n",
    "                       default=1000,\n",
    "                       help=\"Validation interval\")\n",
    "\n",
    "train_arg.add_argument(\"--rep_intv\", type=int,\n",
    "                       default=150,\n",
    "                       help=\"Report interval\")\n",
    "\n",
    "train_arg.add_argument(\"--log_dir\", type=str,\n",
    "                       default=\"/home/yufeng/projects/rrg-kyi/yufeng/image_classification/unet/data/loss_plot\",\n",
    "                       help=\"Directory to save logs and current model\")\n",
    "\n",
    "train_arg.add_argument(\"--save_dir\", type=str,\n",
    "                       default=\"/home/yufeng/projects/rrg-kyi/yufeng/image_classification/unet/save\",\n",
    "                       help=\"Directory to save the best model\")\n",
    "\n",
    "train_arg.add_argument(\"--resume\", type=str2bool,\n",
    "                       default=True,\n",
    "                       help=\"Whether to resume training from existing checkpoint\")\n",
    "# ----------------------------------------\n",
    "# Arguments for model\n",
    "model_arg = add_argument_group(\"Model\")\n",
    "\n",
    "model_arg.add_argument(\"--feature_type\", type=str,\n",
    "                       default=\"hog\",\n",
    "                       choices=[\"hog\", \"h_histogram\", \"rgb\"],\n",
    "                       help=\"Type of feature to be used\")\n",
    "\n",
    "model_arg.add_argument(\"--loss_type\", type=str,\n",
    "                       default=\"cross_entropy\",\n",
    "                       choices=[\"cross_entropy\", \"svm\"],\n",
    "                       help=\"Type of data loss to be used\")\n",
    "\n",
    "model_arg.add_argument(\"--normalize\", type=str2bool,\n",
    "                       default=True,\n",
    "                       help=\"Whether to normalize with mean/std or not\")\n",
    "\n",
    "model_arg.add_argument(\"--l2_reg\", type=float,\n",
    "                       default=1e-3,\n",
    "                       help=\"L2 Regularization strength\")\n",
    "\n",
    "model_arg.add_argument(\"--num_unit\", type=int,\n",
    "                       default=64,\n",
    "                       help=\"Number of neurons in the hidden layer\")\n",
    "\n",
    "model_arg.add_argument(\"--num_hidden\", type=int,\n",
    "                       default=3,\n",
    "                       help=\"Number of hidden layers\")\n",
    "\n",
    "model_arg.add_argument(\"--num_class\", type=int,\n",
    "                       default=10,\n",
    "                       help=\"Number of classes in the dataset\")\n",
    "\n",
    "model_arg.add_argument(\"--activ_type\", type=str,\n",
    "                       default=\"relu\",\n",
    "                       choices=[\"relu\", \"tanh\"],\n",
    "                       help=\"Activation type\")\n",
    "\n",
    "\n",
    "def get_config():\n",
    "    config, unparsed = parser.parse_known_args()\n",
    "\n",
    "    return config, unparsed\n",
    "\n",
    "\n",
    "def print_usage():\n",
    "    parser.print_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.conv(input)\n",
    "\n",
    "\n",
    "class MyUnet(nn.Module):\n",
    "    def __init__(self,in_ch,out_ch):\n",
    "        super(MyUnet, self).__init__()\n",
    "\n",
    "        self.conv1 = DoubleConv(in_ch, 64)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = DoubleConv(64, 128)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.conv3 = DoubleConv(128, 256)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        self.conv4 = DoubleConv(256, 512)\n",
    "        self.pool4 = nn.MaxPool2d(2)\n",
    "        self.conv5 = DoubleConv(512, 1024)\n",
    "        self.up6 = nn.ConvTranspose2d(1024, 512, 2, stride=2)\n",
    "        self.conv6 = DoubleConv(1024, 512)\n",
    "        self.up7 = nn.ConvTranspose2d(512, 256, 2, stride=2)\n",
    "        self.conv7 = DoubleConv(512, 256)\n",
    "        self.up8 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
    "        self.conv8 = DoubleConv(256, 128)\n",
    "        self.up9 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
    "        self.conv9 = DoubleConv(128, 64)\n",
    "        self.conv10 = nn.Conv2d(64,out_ch, 1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        c1=self.conv1(x)\n",
    "        p1=self.pool1(c1)\n",
    "        c2=self.conv2(p1)\n",
    "        p2=self.pool2(c2)\n",
    "        c3=self.conv3(p2)\n",
    "        p3=self.pool3(c3)\n",
    "        c4=self.conv4(p3)\n",
    "        p4=self.pool4(c4)\n",
    "        c5=self.conv5(p4)\n",
    "        up_6= self.up6(c5)\n",
    "        merge6 = torch.cat([up_6, c4], dim=1)\n",
    "        c6=self.conv6(merge6)\n",
    "        up_7=self.up7(c6)\n",
    "        merge7 = torch.cat([up_7, c3], dim=1)\n",
    "        c7=self.conv7(merge7)\n",
    "        up_8=self.up8(c7)\n",
    "        merge8 = torch.cat([up_8, c2], dim=1)\n",
    "        c8=self.conv8(merge8)\n",
    "        up_9=self.up9(c8)\n",
    "        merge9=torch.cat([up_9,c1],dim=1)\n",
    "        c9=self.conv9(merge9)\n",
    "        c10=self.conv10(c9)\n",
    "        #out = nn.Sigmoid()(c10)\n",
    "        return c10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataWrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PitcairnDataset(data.Dataset):\n",
    "    def __init__(self, config, mode):\n",
    "        # mode is \"train\", \"validation\" or \"test\"\n",
    "        if mode == 'train':\n",
    "            self.config = config\n",
    "            print(\"Loading PitcairnDataset\")\n",
    "            data, label = load_data()\n",
    "            self.data = data\n",
    "            self.label = label\n",
    "            print(\"done.\")\n",
    "        if mode == 'valid':\n",
    "            self.config = config\n",
    "            print(\"Loading validation PitcairnDataset\")\n",
    "            data, label = load_test_data()\n",
    "            self.data = data\n",
    "            self.label = label\n",
    "            print(\"done.\")            \n",
    "    \n",
    "    def __len__(self):\n",
    "        return (self.data.shape[0])\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        data_cur = self.data[index]\n",
    "        # data\n",
    "        data_cur = torch.from_numpy(data_cur.astype(np.float32))\n",
    "        # label\n",
    "        label_cur = self.label[index]\n",
    "        return data_cur, label_cur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # read cfht input images, band u\n",
    "    os.chdir(\"/home/yufeng/projects/rrg-kyi/yufeng/image_classification/data/5_bands/cfht\")\n",
    "    data = []\n",
    "    label = []\n",
    "    x_slice = 128\n",
    "    y_slice = 128\n",
    "    x_num = 78\n",
    "    y_num = 78\n",
    "    count=0\n",
    "    for u_file in glob.glob(\"*.u.fits\"):\n",
    "        file_id = u_file[5:12] # for example: 189.268\n",
    "        # load x\n",
    "        u_data_image = fits.open(u_file, memmap=True)\n",
    "        r_file = \"/home/yufeng/projects/rrg-kyi/yufeng/image_classification/data/5_bands/cfht/CFIS.\"+file_id+\".r.fits\"\n",
    "        r_data_image = fits.open(r_file, memmap=True)\n",
    "        g_file = \"/home/yufeng/projects/rrg-kyi/yufeng/image_classification/data/5_bands/ps/PS1.\"+file_id+\".g.fits\"\n",
    "        g_data_image = fits.open(g_file, memmap=True)\n",
    "        i_file = \"/home/yufeng/projects/rrg-kyi/yufeng/image_classification/data/5_bands/ps/PS1.\"+file_id+\".i.fits\"\n",
    "        i_data_image = fits.open(i_file, memmap=True)\n",
    "        z_file = \"/home/yufeng/projects/rrg-kyi/yufeng/image_classification/data/5_bands/ps/PS1.\"+file_id+\".z.fits\"\n",
    "        z_data_image = fits.open(z_file, memmap=True)\n",
    "        # load y\n",
    "        path = '/home/yufeng/projects/rrg-kyi/yufeng/image_classification/unet/data/train/label/CFIS.'+file_id+'.fits.fz'\n",
    "        label_image = fits.open(path)\n",
    "        # stack 5 channels\n",
    "        for k in range(1,2):\n",
    "            #label_image_blur = skimage.filters.gaussian(np.array(label_image[k].data), sigma=0.4, truncate=3.5, multichannel=True)\n",
    "            for i in range(x_num):\n",
    "                for j in range(y_num):\n",
    "                    x_u = np.array(u_data_image[0].data.T[i*x_slice:(i+1)*x_slice, j*y_slice:(j+1)*y_slice])\n",
    "                    x_r = np.array(r_data_image[0].data.T[i*x_slice:(i+1)*x_slice, j*y_slice:(j+1)*y_slice])\n",
    "                    x_g = np.array(g_data_image[0].data.T[i*x_slice:(i+1)*x_slice, j*y_slice:(j+1)*y_slice])\n",
    "                    x_i = np.array(i_data_image[0].data.T[i*x_slice:(i+1)*x_slice, j*y_slice:(j+1)*y_slice])\n",
    "                    x_z = np.array(z_data_image[0].data.T[i*x_slice:(i+1)*x_slice, j*y_slice:(j+1)*y_slice])\n",
    "                    x = np.stack((x_u, x_r, x_g, x_i, x_z), axis=-1)\n",
    "                    y = np.array(label_image[k].data[i*x_slice:(i+1)*x_slice, j*y_slice:(j+1)*y_slice,:])\n",
    "                    if np.any(y>0.5):\n",
    "                        x = np.nan_to_num(x, nan=-1, posinf=-1, neginf=-1) \n",
    "                        nan_pixel = x == -1\n",
    "                        y[nan_pixel[:,:,:4]] = -1\n",
    "                        data += [x]\n",
    "                        label += [y]\n",
    "\n",
    "        count+=1\n",
    "        print(count)\n",
    "        if count==10:\n",
    "            break\n",
    "    data = np.array(data)\n",
    "\n",
    "    data = np.transpose(data, (0, 3, 1, 2))\n",
    "\n",
    "    label = np.array(label)\n",
    "    label = np.transpose(label, (0, 3, 1, 2))\n",
    "\n",
    "    print(np.array(data).shape)\n",
    "    print(np.array(label).shape)\n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data():\n",
    "    # read cfht input images, band u\n",
    "    os.chdir(\"/home/yufeng/projects/rrg-kyi/yufeng/image_classification/unet/data/test/input/cfht\")\n",
    "    data = []\n",
    "    label = []\n",
    "    x_slice = 128\n",
    "    y_slice = 128\n",
    "    x_num = 78\n",
    "    y_num = 78\n",
    "\n",
    "    for u_file in glob.glob(\"*.u.fits\"):\n",
    "        file_id = u_file[5:12] # for example: 189.268\n",
    "        # load x\n",
    "        u_data_image = fits.open(u_file, memmap=True)\n",
    "        r_file = \"/home/yufeng/projects/rrg-kyi/yufeng/image_classification/unet/data/test/input/cfht/CFIS.\"+file_id+\".r.fits\"\n",
    "        r_data_image = fits.open(r_file, memmap=True)\n",
    "        g_file = \"/home/yufeng/projects/rrg-kyi/yufeng/image_classification/unet/data/test/input/ps/PS1.\"+file_id+\".g.fits\"\n",
    "        g_data_image = fits.open(g_file, memmap=True)\n",
    "        i_file = \"/home/yufeng/projects/rrg-kyi/yufeng/image_classification/unet/data/test/input/ps/PS1.\"+file_id+\".i.fits\"\n",
    "        i_data_image = fits.open(i_file, memmap=True)\n",
    "        z_file = \"/home/yufeng/projects/rrg-kyi/yufeng/image_classification/unet/data/test/input/ps/PS1.\"+file_id+\".z.fits\"\n",
    "        z_data_image = fits.open(z_file, memmap=True)\n",
    "        # load y\n",
    "        path = '/home/yufeng/projects/rrg-kyi/yufeng/image_classification/unet/data/test/label/CFIS.'+file_id+'.fits.fz'\n",
    "        label_image = fits.open(path)\n",
    "        # stack 5 channels\n",
    "        for k in range(1,2):\n",
    "            #label_image_blur = skimage.filters.gaussian(np.array(label_image[k].data), sigma=0.4, truncate=3.5, multichannel=True)\n",
    "            for i in range(x_num):\n",
    "                for j in range(y_num):\n",
    "                    x_u = np.array(u_data_image[0].data.T[i*x_slice:(i+1)*x_slice, j*y_slice:(j+1)*y_slice])\n",
    "                    x_r = np.array(r_data_image[0].data.T[i*x_slice:(i+1)*x_slice, j*y_slice:(j+1)*y_slice])\n",
    "                    x_g = np.array(g_data_image[0].data.T[i*x_slice:(i+1)*x_slice, j*y_slice:(j+1)*y_slice])\n",
    "                    x_i = np.array(i_data_image[0].data.T[i*x_slice:(i+1)*x_slice, j*y_slice:(j+1)*y_slice])\n",
    "                    x_z = np.array(z_data_image[0].data.T[i*x_slice:(i+1)*x_slice, j*y_slice:(j+1)*y_slice])\n",
    "                    x = np.stack((x_u, x_r, x_g, x_i, x_z), axis=-1)\n",
    "                    y = np.array(label_image[k].data[i*x_slice:(i+1)*x_slice, j*y_slice:(j+1)*y_slice,:])\n",
    "                    if np.any(y>0.5):\n",
    "                        x = np.nan_to_num(x, nan=-1, posinf=-1, neginf=-1) \n",
    "                        nan_pixel = x == -1\n",
    "                        y[nan_pixel[:,:,:4]] = -1\n",
    "                        data += [x]\n",
    "                        label += [y]\n",
    "        break\n",
    "    data = np.array(data)\n",
    "    \n",
    "    data = np.transpose(data, (0, 3, 1, 2))\n",
    "\n",
    "    label = np.array(label)\n",
    "    label = np.transpose(label, (0, 3, 1, 2))\n",
    "\n",
    "    print(np.array(data).shape)\n",
    "    print(np.array(label).shape)\n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config):\n",
    "    train_data = PitcairnDataset(config, mode=\"train\")\n",
    "    valid_data = PitcairnDataset(config, mode=\"valid\")\n",
    "    inc = 5\n",
    "    outc = 4\n",
    "    best_acc = 0\n",
    "    model = MyUnet(inc, outc)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "    \n",
    "    tr_data_loader = DataLoader(\n",
    "        dataset=train_data,\n",
    "        batch_size=config.batch_size,\n",
    "        num_workers=2,\n",
    "        shuffle=True)\n",
    "    \n",
    "    va_data_loader = DataLoader(\n",
    "        dataset=valid_data,\n",
    "        batch_size=config.batch_size,\n",
    "        num_workers=2,\n",
    "        shuffle=False)\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    #loss = nn.PoissonNLLLoss()\n",
    "    loss = nn.KLDivLoss()\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr = config.learning_rate)\n",
    "    \n",
    "    bestmodel_file = os.path.join(config.save_dir, \"best_model.pth\")\n",
    "    \n",
    "    iter_idx = -1\n",
    "    tr_writer = SummaryWriter(\n",
    "        log_dir=os.path.join(config.log_dir, \"train\"))\n",
    "    va_writer = SummaryWriter(\n",
    "        log_dir=os.path.join(config.log_dir, \"valid\"))\n",
    "    acc_writer = SummaryWriter(\n",
    "        log_dir=os.path.join(config.log_dir, \"accuracy\")) \n",
    "    total_train_loss = 0\n",
    "    total_val_loss = []\n",
    "    train_count = 0\n",
    "    val_count = 0\n",
    "    for epoch in range(config.num_epoch):\n",
    "        print(epoch)\n",
    "\n",
    "        prefix = \"Training Epoch {:3d}: \".format(epoch)\n",
    "        for data in tr_data_loader:\n",
    "            iter_idx += 1\n",
    "            x, y = data\n",
    "            \n",
    "            if torch.cuda.is_available():\n",
    "                x = x.cuda()\n",
    "                y = y.cuda()\n",
    "            \n",
    "            logits = model.forward(x)\n",
    "            \n",
    "            m = nn.Softmax2d()\n",
    "            logits = m(logits)\n",
    "            logits = torch.log(logits)\n",
    "            # data: 0.25, nan, label pixel\n",
    "            \n",
    "            temp_x = logits.detach().cpu().numpy()\n",
    "            temp_y = y.detach().cpu().numpy()\n",
    "            \n",
    "            pixel1 = temp_y != 0.25\n",
    "            pixel2 = temp_y != -1\n",
    "            label_pixel = pixel1 & pixel2\n",
    "            nan_pixel = temp_y == -1\n",
    "            other_pixel = temp_y == 0.25\n",
    "     \n",
    "            weights_nan_pixel = 0\n",
    "\n",
    "            weights_label = float(temp_y[other_pixel].shape[0] / (temp_y[label_pixel].shape[0]+temp_y[other_pixel].shape[0]))\n",
    "            weights_other = float(temp_y[label_pixel].shape[0] / (temp_y[label_pixel].shape[0]+temp_y[other_pixel].shape[0]))\n",
    "            logits = logits.float()\n",
    "            y = y.float()\n",
    "            output_loss = weights_label*loss(logits[[label_pixel]], y[[label_pixel]])+weights_other*loss(logits[[other_pixel]], y[[other_pixel]])\n",
    "\n",
    "            output_loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            total_train_loss += output_loss\n",
    "            train_count += 1\n",
    "            if iter_idx % config.rep_intv == 0:\n",
    "                mean_output_loss = total_train_loss/train_count\n",
    "                tr_writer.add_scalar(\"loss\", mean_output_loss, global_step=iter_idx)\n",
    "                print(\"training loss: \" + str(mean_output_loss))\n",
    "                #print('prediction: ')\n",
    "                #print(np.exp(temp_x)[label_pixel])\n",
    "                #print('label: ')\n",
    "                #print(temp_y[label_pixel])\n",
    "                total_train_loss = 0\n",
    "                train_count = 0\n",
    "                total_count = 0\n",
    "                true_count = 0\n",
    "                wrong_count = 0\n",
    "                model = model.eval()\n",
    "                for data in va_data_loader:\n",
    "                    x, y = data\n",
    "                    if torch.cuda.is_available():\n",
    "                        x = x.cuda()\n",
    "                        y = y.cuda()\n",
    "                    with torch.no_grad():\n",
    "                        logits = model.forward(x)\n",
    "            \n",
    "                        m = nn.Softmax2d()\n",
    "                        logits = m(logits)\n",
    "                        logits = torch.log(logits)\n",
    "\n",
    "                        temp_x = logits.detach().cpu().numpy()\n",
    "                        temp_y = y.detach().cpu().numpy()\n",
    "\n",
    "                        pixel1 = temp_y != 0.25\n",
    "                        pixel2 = temp_y != -1\n",
    "                        label_pixel = pixel1 & pixel2\n",
    "                        nan_pixel = temp_y == -1\n",
    "                        other_pixel = temp_y == 0.25\n",
    "\n",
    "                        weights_nan_pixel = 0\n",
    "                        \n",
    "                        # accuracy\n",
    "                        pred = torch.argmax(torch.exp(logits)[[label_pixel]])\n",
    "                        yy = torch.argmax(y[[label_pixel]])\n",
    "                        acc = yy.eq(pred).cpu().sum()\n",
    "                        true_count += acc.cpu().numpy()\n",
    "                        wrong_count += (acc.cpu().numpy()-1)\n",
    "                        total_count += 1\n",
    "                        weights_label = temp_y[other_pixel].shape[0] / (temp_y[label_pixel].shape[0]+temp_y[other_pixel].shape[0])\n",
    "                        weights_other = temp_y[label_pixel].shape[0] / (temp_y[label_pixel].shape[0]+temp_y[other_pixel].shape[0])\n",
    "\n",
    "                        va_output_loss = weights_label*loss(logits[[label_pixel]], y[[label_pixel]])+weights_other*loss(logits[[other_pixel]], y[[other_pixel]])\n",
    "                        if (va_output_loss == math.inf) | (math.isnan(va_output_loss)):\n",
    "                            continue\n",
    "                        total_val_loss += [va_output_loss.cpu().numpy()]\n",
    "                        val_count += 1\n",
    "                #print('validation prediction: ')\n",
    "                #print(np.exp(temp_x)[label_pixel])\n",
    "                #print('validation label: ')\n",
    "                #print(temp_y[label_pixel])\n",
    "                        mean_val_loss = np.mean(total_val_loss)\n",
    "                print('validation loss:'+str(mean_val_loss))\n",
    "                va_writer.add_scalar(\"validation loss\", mean_val_loss, global_step=iter_idx)\n",
    "                accuracy = (true_count/total_count)*100.0\n",
    "                if accuracy > best_acc:\n",
    "                    best_acc = accuracy\n",
    "                    torch.save({\n",
    "                        \"model\": model.state_dict(),\n",
    "                    }, bestmodel_file)\n",
    "                acc_writer.add_scalar(\"accuracy \", accuracy, global_step=iter_idx)\n",
    "                print('accuracy: ' + str(accuracy) + '%')\n",
    "                total_val_loss = []\n",
    "                val_count = 0\n",
    "                model = model.train()\n",
    "    print('best accuracy: ' + str(best_acc) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(config):\n",
    "    galaxy = 0\n",
    "    quasar = 0\n",
    "    star = 0\n",
    "    predict_galaxy = 0\n",
    "    predict_quasar = 0\n",
    "    predict_star = 0\n",
    "    \n",
    "    inc = 5\n",
    "    outc = 4\n",
    "    total_val_loss = []\n",
    "    val_count = 0\n",
    "    total_count = 0\n",
    "    true_count = 0\n",
    "    wrong_count = 0\n",
    "    hdu_list = []\n",
    "    valid_data = PitcairnDataset(config, mode=\"valid\")\n",
    "    \n",
    "    va_data_loader = DataLoader(\n",
    "        dataset=valid_data,\n",
    "        batch_size=config.batch_size,\n",
    "        num_workers=2,\n",
    "        shuffle=False)\n",
    "    \n",
    "    model = MyUnet(inc, outc)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "    \n",
    "    load_res = torch.load(os.path.join(config.save_dir, \"best_model.pth\"))\n",
    "    model.load_state_dict(load_res[\"model\"])\n",
    "    model.eval()\n",
    "    #loss = nn.PoissonNLLLoss()\n",
    "    loss = nn.KLDivLoss()\n",
    "    \n",
    "    for data in va_data_loader:\n",
    "        x, y = data\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "        with torch.no_grad():            \n",
    "            logits = model.forward(x)\n",
    "            m = nn.Softmax2d()\n",
    "            logits = m(logits)\n",
    "            logits = torch.log(logits)\n",
    " \n",
    "            temp_x = logits.detach().cpu().numpy()\n",
    "            temp_y = y.detach().cpu().numpy()\n",
    "\n",
    "            pixel1 = temp_y != 0.25\n",
    "            pixel2 = temp_y != -1\n",
    "            label_pixel = pixel1 & pixel2\n",
    "            nan_pixel = temp_y == -1\n",
    "            other_pixel = temp_y == 0.25\n",
    "            \n",
    "            label_class_index = np.where((temp_y != 0.25) & (temp_y != -1))\n",
    "            label_class = temp_y[np.where((temp_y != 0.25) & (temp_y != -1))]\n",
    "            label_x = label_class_index[3][0]\n",
    "            label_y = label_class_index[2][0]\n",
    "            label_class_id = np.argmax(label_class)\n",
    "\n",
    "            image_u = np.transpose(x.detach().cpu().numpy(), (0, 2, 3, 1))[0,:,:,0]\n",
    "            image_r = np.transpose(x.detach().cpu().numpy(), (0, 2, 3, 1))[0,:,:,1]\n",
    "            image_g = np.transpose(x.detach().cpu().numpy(), (0, 2, 3, 1))[0,:,:,2]\n",
    "            image_i = np.transpose(x.detach().cpu().numpy(), (0, 2, 3, 1))[0,:,:,3]\n",
    "            image_z = np.transpose(x.detach().cpu().numpy(), (0, 2, 3, 1))[0,:,:,4]\n",
    "            # plot original images\n",
    "            norm = ImageNormalize(image, interval=ZScaleInterval(),\n",
    "                      stretch=SqrtStretch())\n",
    "            plt.imshow(image_r, cmap='gray', norm=norm)\n",
    "            plt.show()\n",
    "            image_ls = [image_u, image_r, image_g, image_i, image_z]\n",
    "            band_ls = ['u','r', 'g', 'i', 'z']\n",
    "            fig = plt.figure(figsize=(25, 25))\n",
    "            ax = []\n",
    "            count_i = 0\n",
    "            #circle2 = plt.Circle((5, 5), 0.5, color='b', fill=False)\n",
    "            tmp = np.array(np.where(np.exp(temp_x) >= 0.5))\n",
    "\n",
    "            quasar_class_x = []\n",
    "            quasar_class_y = []\n",
    "            star_class_x = []\n",
    "            star_class_y = []\n",
    "            galaxy_class_x = []\n",
    "            galaxy_class_y = []\n",
    "            \n",
    "            for (band,image) in zip(band_ls,image_ls):\n",
    "                tmp_ax = fig.add_subplot(1, 5, count_i+1)\n",
    "                ax.append(tmp_ax)\n",
    "                ax[-1].set_title(\"band:\"+str(band))\n",
    "                # plot label circle\n",
    "                if label_class_id == 0:\n",
    "                    circle = plt.Circle((label_x, label_y), 15, color='g', fill=False)\n",
    "                    tmp_ax.add_patch(circle)\n",
    "                elif label_class_id == 1:\n",
    "                    circle = plt.Circle((label_x, label_y), 15, color='r', fill=False)\n",
    "                    tmp_ax.add_patch(circle)\n",
    "                elif label_class_id == 2:\n",
    "                    circle = plt.Circle((label_x, label_y), 15, color='b', fill=False)\n",
    "                    tmp_ax.add_patch(circle)\n",
    "\n",
    "                # plot prediction circle\n",
    "                if tmp.size > 0:\n",
    "                    for i in range(tmp.shape[1]):\n",
    "                        if tmp[1,i] == 0: # 2: galaxy 1: star  0: quasar\n",
    "                            #print('circle('+str(tmp[3,i])+','+str(tmp[2,i])+',10) # color = green')\n",
    "                            circle = plt.Circle((tmp[3,i], tmp[2,i]), 0.5, color='g', fill=False)\n",
    "                            quasar_class_x.append(tmp[3,i])\n",
    "                            quasar_class_y.append(120-tmp[2,i])\n",
    "                            tmp_ax.add_patch(circle)\n",
    "\n",
    "                        elif tmp[1,i] == 1:\n",
    "                            #print('circle('+str(tmp[3,i])+','+str(tmp[2,i])+',10) # color = red')\n",
    "                            circle = plt.Circle((tmp[3,i], tmp[2,i]), 0.5, color='r', fill=False)\n",
    "                            star_class_x.append(tmp[3,i])\n",
    "                            star_class_y.append(120-tmp[2,i])\n",
    "                            tmp_ax.add_patch(circle)\n",
    "\n",
    "                        elif tmp [1,i] == 2:\n",
    "                            #print('circle('+str(tmp[3,i])+','+str(tmp[2,i])+',10) # color = blue')\n",
    "                            circle = plt.Circle((tmp[3,i], tmp[2,i]), 0.5, color='b', fill=False)\n",
    "                            galaxy_class_x.append(tmp[3,i])\n",
    "                            galaxy_class_y.append(120-tmp[2,i])\n",
    "                            tmp_ax.add_patch(circle)\n",
    "\n",
    "                plt.imshow(image, cmap='gray')\n",
    "                count_i += 1\n",
    "            \n",
    "            plt.show() \n",
    "\n",
    "            plt.xlim(0,128)\n",
    "            plt.ylim(0,128)\n",
    "            sns.set_style(\"white\")\n",
    "            sns.kdeplot(quasar_class_x, quasar_class_y, cmap=\"Greens\", shade=True, shade_lowest=True, )\n",
    "            plt.show()\n",
    "\n",
    "            plt.xlim(0,128)\n",
    "            plt.ylim(0,128)\n",
    "            sns.kdeplot(star_class_x, star_class_y, cmap=\"Reds\", shade=True, shade_lowest=True, )\n",
    "            plt.show()\n",
    "\n",
    "            plt.xlim(0,128)\n",
    "            plt.ylim(0,128)\n",
    "            sns.kdeplot(galaxy_class_x, galaxy_class_y, cmap=\"Blues\", shade=True, shade_lowest=True, )\n",
    "            plt.show()\n",
    "            #circle(1046.9408690733712,1428.1269110415067,5) # color = blue\n",
    "            #primary = fits.PrimaryHDU()\n",
    "            #hdu_list.append(primary)\n",
    "            #hdu = fits.ImageHDU(image_x)\n",
    "            #hdu_list.append(hdu)\n",
    "            #savename = '/home/yufeng/projects/rrg-kyi/yufeng/image_classification/unet/visualization/sample_u.fits.fz'\n",
    "            #hdul = fits.HDUList(hdu_list)\n",
    "            #hdul.writeto(savename)\n",
    "\n",
    "            weights_nan_pixel = 0\n",
    "            pred = torch.argmax(torch.exp(logits)[[label_pixel]])\n",
    "            yy = torch.argmax(y[[label_pixel]])\n",
    "\n",
    "            acc = yy.eq(pred).cpu().sum()\n",
    "            true_count += acc.cpu().numpy()\n",
    "            wrong_count += (acc.cpu().numpy()-1)\n",
    "            total_count += 1\n",
    "            weights_label = temp_y[other_pixel].shape[0] / (temp_y[label_pixel].shape[0]+temp_y[other_pixel].shape[0])\n",
    "            weights_other = temp_y[label_pixel].shape[0] / (temp_y[label_pixel].shape[0]+temp_y[other_pixel].shape[0])\n",
    "\n",
    "            va_output_loss = weights_label*loss(logits[[label_pixel]], y[[label_pixel]])+weights_other*loss(logits[[other_pixel]], y[[other_pixel]])\n",
    "            if (va_output_loss == math.inf) | (math.isnan(va_output_loss)):\n",
    "                continue\n",
    "            total_val_loss += [va_output_loss.cpu().numpy()]\n",
    "            val_count += 1\n",
    "            mean_val_loss = np.mean(total_val_loss)\n",
    "            \n",
    "    print('test loss: '+str(mean_val_loss))\n",
    "    accuracy = (true_count/total_count)*100.0\n",
    "    print('accuracy: ' + str(accuracy))\n",
    "    total_val_loss = []\n",
    "    val_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(config):\n",
    "    galaxy = 0\n",
    "    quasar = 0\n",
    "    star = 0\n",
    "    predict_galaxy = 0\n",
    "    predict_quasar = 0\n",
    "    predict_star = 0\n",
    "    \n",
    "    inc = 5\n",
    "    outc = 4\n",
    "    total_val_loss = []\n",
    "    val_count = 0\n",
    "    total_count = 0\n",
    "    true_count = 0\n",
    "    wrong_count = 0\n",
    "    hdu_list = []\n",
    "    valid_data = PitcairnDataset(config, mode=\"valid\")\n",
    "    \n",
    "    va_data_loader = DataLoader(\n",
    "        dataset=valid_data,\n",
    "        batch_size=config.batch_size,\n",
    "        num_workers=2,\n",
    "        shuffle=False)\n",
    "    \n",
    "    model = MyUnet(inc, outc)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "    \n",
    "    load_res = torch.load(os.path.join(config.save_dir, \"best_model.pth\"))\n",
    "    model.load_state_dict(load_res[\"model\"])\n",
    "    model.eval()\n",
    "    #loss = nn.PoissonNLLLoss()\n",
    "    loss = nn.KLDivLoss()\n",
    "    \n",
    "    for data in va_data_loader:\n",
    "        x, y = data\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "        with torch.no_grad():            \n",
    "            logits = model.forward(x)\n",
    "            m = nn.Softmax2d()\n",
    "            logits = m(logits)\n",
    "            logits = torch.log(logits)\n",
    " \n",
    "            temp_x = logits.detach().cpu().numpy()\n",
    "            temp_y = y.detach().cpu().numpy()\n",
    "\n",
    "            pixel1 = temp_y != 0.25\n",
    "            pixel2 = temp_y != -1\n",
    "            label_pixel = pixel1 & pixel2\n",
    "            nan_pixel = temp_y == -1\n",
    "            other_pixel = temp_y == 0.25\n",
    "            \n",
    "            weights_nan_pixel = 0\n",
    "            pred = torch.argmax(torch.exp(logits)[[label_pixel]])\n",
    "            yy = torch.argmax(y[[label_pixel]])\n",
    "            \n",
    "            if yy == 0:\n",
    "                quasar+=1\n",
    "                if pred == 0:\n",
    "                    predict_quasar+=1\n",
    "            elif yy == 1:\n",
    "                star+=1\n",
    "                if pred == 1:\n",
    "                    predict_star+=1\n",
    "            elif yy == 2:\n",
    "                galaxy+=1\n",
    "                if pred == 2:\n",
    "                    predict_galaxy+=1\n",
    "            \n",
    "            acc = yy.eq(pred).cpu().sum()\n",
    "            true_count += acc.cpu().numpy()\n",
    "            wrong_count += (acc.cpu().numpy()-1)\n",
    "            total_count += 1\n",
    "            weights_label = temp_y[other_pixel].shape[0] / (temp_y[label_pixel].shape[0]+temp_y[other_pixel].shape[0])\n",
    "            weights_other = temp_y[label_pixel].shape[0] / (temp_y[label_pixel].shape[0]+temp_y[other_pixel].shape[0])\n",
    "\n",
    "            va_output_loss = weights_label*loss(logits[[label_pixel]], y[[label_pixel]])+weights_other*loss(logits[[other_pixel]], y[[other_pixel]])\n",
    "            if (va_output_loss == math.inf) | (math.isnan(va_output_loss)):\n",
    "                continue\n",
    "            total_val_loss += [va_output_loss.cpu().numpy()]\n",
    "            val_count += 1\n",
    "            mean_val_loss = np.mean(total_val_loss)\n",
    "            \n",
    "    print('test loss: '+str(mean_val_loss))\n",
    "    accuracy = (true_count/total_count)*100.0\n",
    "    print('accuracy: ' + str(accuracy))\n",
    "    total_val_loss = []\n",
    "    val_count = 0\n",
    "    \n",
    "    print('there are ' + str(total_count) + ' objects in the test set')\n",
    "    print('there are ' + str(quasar) + ' quasars totally, and ' + str(predict_quasar) + ' of them are predicted as quasar')\n",
    "    print('there are ' + str(star) + ' stars totally, and ' + str(predict_star) + ' of them are predicted as star')\n",
    "    print('there are ' + str(galaxy) + ' galaxies totally, and ' + str(predict_galaxy) + ' of them are predicted as galaxy')\n",
    "    print('overall precision is '+ str(accuracy))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--mode {train,test}] [--data_dir DATA_DIR]\n",
      "                             [--learning_rate LEARNING_RATE]\n",
      "                             [--batch_size BATCH_SIZE] [--num_epoch NUM_EPOCH]\n",
      "                             [--val_intv VAL_INTV] [--rep_intv REP_INTV]\n",
      "                             [--log_dir LOG_DIR] [--save_dir SAVE_DIR]\n",
      "                             [--resume RESUME]\n",
      "                             [--feature_type {hog,h_histogram,rgb}]\n",
      "                             [--loss_type {cross_entropy,svm}]\n",
      "                             [--normalize NORMALIZE] [--l2_reg L2_REG]\n",
      "                             [--num_unit NUM_UNIT] [--num_hidden NUM_HIDDEN]\n",
      "                             [--num_class NUM_CLASS]\n",
      "                             [--activ_type {relu,tanh}]\n",
      "Loading validation PitcairnDataset\n",
      "(248, 5, 128, 128)\n",
      "(248, 4, 128, 128)\n",
      "done.\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'image' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-c582804bd159>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-c582804bd159>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown run mode \\\"{}\\\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-6a5f46ee94d5>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mimage_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;31m# plot original images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             norm = ImageNormalize(image, interval=ZScaleInterval(),\n\u001b[0m\u001b[1;32m     69\u001b[0m                       stretch=SqrtStretch())\n\u001b[1;32m     70\u001b[0m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'image' referenced before assignment"
     ]
    }
   ],
   "source": [
    "def main(config):\n",
    "    \"\"\"The main function.\"\"\"\n",
    "\n",
    "    if config.mode == \"train\":\n",
    "        train(config)\n",
    "    elif config.mode == \"test\":\n",
    "        test(config)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown run mode \\\"{}\\\"\".format(config.mode))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # Parse configuration\n",
    "    config, unparsed = get_config()\n",
    "    # If we have unparsed arguments, print usage and exit\n",
    "    if len(unparsed) > 0:\n",
    "        print_usage()\n",
    "        exit(1)\n",
    "\n",
    "    main(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = np.arange(65536).reshape((256, 256))\n",
    "\n",
    "# Create an ImageNormalize object\n",
    "norm = ImageNormalize(image, interval=ZScaleInterval(),\n",
    "                      stretch=SqrtStretch())\n",
    "\n",
    "# or equivalently using positional arguments\n",
    "# norm = ImageNormalize(image, MinMaxInterval(), SqrtStretch())\n",
    "\n",
    "# Display the image\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "im = ax.imshow(image, origin='lower', norm=norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
